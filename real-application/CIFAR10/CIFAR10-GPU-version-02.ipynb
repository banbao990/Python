{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.加载并标准化CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# author:banbao\n",
    "# version:2\n",
    "# Maxpooling -> FractionalMaxPool2d\n",
    "\n",
    "# ToTensor 可以把一个PIL或numpy图片转为torch.Tensor\n",
    "# Normaize 正则化(预处理)\n",
    "# torchvision.transforms.Normalize(mean, std, inplace=False)\n",
    "# input[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "# 如下示例,输入原本为 [0,1] -> [-1,1]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# 训练集\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "# 测试集\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "# 类别\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Split: train\n",
       "    Root Location: ./data\n",
       "    Transforms (if any): Compose(\n",
       "                             ToTensor()\n",
       "                             Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "                         )\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.定义卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16\n",
    "# 原始:CCP,CCP,CCCP,CCCP,CCCP,softmax\n",
    "# 卷积核大小都为 3*3,步长为 1, padding=1(保持图片大小不变)\n",
    "# N=4,每组 4 个样本\n",
    "# 每个样本过程如下\n",
    "# 1. 3*32*32    ->  卷积核个数:64\n",
    "# 2. 64*32*32   ->  卷积核个数:64\n",
    "# 3. 64*32*32   ->  maxpool:2*2\n",
    "# 4. 64*16*16   ->  卷积核个数:128\n",
    "# 5. 128*16*16  ->  卷积核个数:128\n",
    "# 6. 128*16*16  ->  maxpool:2*2\n",
    "# 7. 128*8*8    ->  卷积核个数:256\n",
    "# 8. 256*8*8    ->  卷积核个数:256\n",
    "# 9. 256*8*8    ->  卷积核个数:256\n",
    "#10. 256*8*8    ->  maxpool:2*2\n",
    "#11. 256*4*4    ->  卷积核个数:512\n",
    "#12. 512*4*4    ->  卷积核个数:512\n",
    "#13. 512*4*4    ->  卷积核个数:512\n",
    "#14. 512*4*4    ->  maxpool:2*2\n",
    "#15. 512*2*2    ->  卷积核个数:512\n",
    "#16. 512*2*2    ->  卷积核个数:512\n",
    "#17. 512*2*2    ->  卷积核个数:512\n",
    "#18. 512*2*2    ->  maxpool:2*2\n",
    "#19. 512*1*1    ->  Linear:512->10\n",
    "#20. 1\n",
    "\n",
    "# torch.nn.Conv2d(in_channels, out_channels, kernel_size, \n",
    "# stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "\n",
    "# torch.nn.AvgPool2d(kernel_size, stride=None, padding=0, \n",
    "# ceil_mode=False, count_include_pad=True, divisor_override=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义卷积神经网络\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    # 构造函数\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 网络层\n",
    "        self.layers = nn.Sequential(\n",
    "            # CCP\n",
    "            nn.Conv2d(3,  64, 3, stride=1, padding=1),\n",
    "            # 正则化\n",
    "            nn.BatchNorm2d(64),\n",
    "            # 激活函数\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.FractionalMaxPool2d(kernel_size=2, output_ratio=(0.5, 0.5)),\n",
    "            # CCP\n",
    "            nn.Conv2d(64, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128,128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.FractionalMaxPool2d(kernel_size=2, output_ratio=(0.5, 0.5)),\n",
    "            # CCCP\n",
    "            nn.Conv2d(128,256, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.FractionalMaxPool2d(kernel_size=2, output_ratio=(0.5, 0.5)),\n",
    "            # CCCP\n",
    "            nn.Conv2d(256,512, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.FractionalMaxPool2d(kernel_size=2, output_ratio=(0.5, 0.5)),\n",
    "            # CCCP\n",
    "            nn.Conv2d(512,512, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.FractionalMaxPool2d(kernel_size=2, output_ratio=(0.5, 0.5))\n",
    "        )\n",
    "        # Linear\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "    \n",
    "    # 网络层的构建\n",
    "    def forward(self, x):\n",
    "        output = self.layers(x)\n",
    "        # 一个 batch 有4个样本\n",
    "        output = output.view(4,512)\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): FractionalMaxPool2d()\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): FractionalMaxPool2d()\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace)\n",
      "    (23): FractionalMaxPool2d()\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace)\n",
      "    (33): FractionalMaxPool2d()\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace)\n",
      "    (43): FractionalMaxPool2d()\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.定义损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉熵\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 随机梯度下降(momentum)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.训练网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "useGPU = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 测试函数(计算ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAcc(isTrain):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in trainloader if isTrain else testloader:\n",
    "            images, labels = data\n",
    "            if useGPU:\n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 1.0*correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 不同类型的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showSpecificClass():\n",
    "    # 看看不同类别的准确率\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            if useGPU:\n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "                \n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = []\n",
    "def train(start, end):\n",
    "    # 多次迭代\n",
    "    for epoch in range(start, end):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # 输入\n",
    "            inputs, labels = data\n",
    "            if useGPU:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "            # 梯度清0\n",
    "            optimizer.zero_grad()\n",
    "            # 训练\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # 损失函数\n",
    "            running_loss += loss.item()\n",
    "            # 每间隔 500*4 样本输出一个示意符号\n",
    "            if i % 500 == 499:\n",
    "                print(\"#\",end=\"\")\n",
    "        # 输出当前的正确率\n",
    "        trainAcc = calcAcc(True)\n",
    "        testAcc = calcAcc(False)\n",
    "        now = [trainAcc, testAcc, epoch]\n",
    "        print(\"\\n[{}],loss: {}, train acc: {}, test acc: {}\".format(epoch, running_loss, trainAcc, testAcc))\n",
    "        # if((epoch % 10 == 0) or (epoch == end-1)):\n",
    "        if not os.path.exists(\"./model\"):\n",
    "            os.makedirs('./model')\n",
    "        PATH = \"./model/GPU-model-VGG-02-trainacc-{}-testacc-{}-epoch-{}.pkl\".format(now[0], now[1], now[2])\n",
    "        torch.save(net.state_dict(), PATH)\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING GPU(CUDA)!\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "if useGPU:\n",
    "    net = net.cuda()\n",
    "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    criterion.cuda()\n",
    "    # optimizer.cuda()\n",
    "    print(\"USING GPU(CUDA)!\")\n",
    "else:\n",
    "    print(\"USING CPU!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取已经保存的模型\n",
    "# PATH = \"./model/GPU-model-VGG-02-trainacc-0.9921-testacc-0.8291-epoch-24.pkl\"\n",
    "# net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "[0],loss: 18906.116727799177, train acc: 0.64886, test acc: 0.6337\n",
      "#########################\n",
      "[1],loss: 11948.10486382246, train acc: 0.7267, test acc: 0.6953\n",
      "#########################\n",
      "[2],loss: 9281.27218541503, train acc: 0.78816, test acc: 0.7493\n",
      "#########################\n",
      "[3],loss: 7555.112104207277, train acc: 0.8375, test acc: 0.7756\n",
      "#########################\n",
      "[4],loss: 6242.46597468853, train acc: 0.85568, test acc: 0.7833\n",
      "#########################\n",
      "[5],loss: 5178.600890517235, train acc: 0.88784, test acc: 0.8045\n",
      "#########################\n",
      "[6],loss: 4297.028632432222, train acc: 0.91598, test acc: 0.8161\n",
      "#########################\n",
      "[7],loss: 3523.701321065426, train acc: 0.9265, test acc: 0.8126\n",
      "#########################\n",
      "[8],loss: 2886.300848901272, train acc: 0.94244, test acc: 0.8213\n",
      "#########################\n",
      "[9],loss: 2397.139822304249, train acc: 0.9487, test acc: 0.8117\n",
      "#########################\n",
      "[10],loss: 1961.1240290403366, train acc: 0.97098, test acc: 0.8302\n",
      "#########################\n",
      "[11],loss: 1654.1217524409294, train acc: 0.96804, test acc: 0.8179\n",
      "#########################\n",
      "[12],loss: 1277.1368697881699, train acc: 0.97642, test acc: 0.824\n",
      "#########################\n",
      "[13],loss: 1048.2373838722706, train acc: 0.9741, test acc: 0.8213\n",
      "#########################\n",
      "[14],loss: 992.0674051046371, train acc: 0.98188, test acc: 0.8241\n",
      "#########################\n",
      "[15],loss: 791.7208023965359, train acc: 0.98492, test acc: 0.8301\n",
      "#########################\n",
      "[16],loss: 712.9692198634148, train acc: 0.98574, test acc: 0.8279\n",
      "#########################\n",
      "[17],loss: 617.9373843073845, train acc: 0.98544, test acc: 0.8313\n",
      "#########################\n",
      "[18],loss: 479.6598817706108, train acc: 0.98982, test acc: 0.83\n",
      "#########################\n",
      "[19],loss: 483.758426964283, train acc: 0.98828, test acc: 0.8301\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "# train(0,2)\n",
    "# train(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainAcc:[1]running_loss:0.51846"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "[20],loss: 441.61659610271454, train acc: 0.9905, test acc: 0.8352\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train(20,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "[21],loss: 388.17329066991806, train acc: 0.99384, test acc: 0.8343\n",
      "#########################\n",
      "[22],loss: 330.47664684057236, train acc: 0.99368, test acc: 0.8368\n",
      "#########################\n",
      "[23],loss: 236.7883815765381, train acc: 0.99148, test acc: 0.8283\n",
      "#########################\n",
      "[24],loss: 301.6002177596092, train acc: 0.9921, test acc: 0.8291\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train(21,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch-1.0.0",
   "language": "python",
   "name": "pytorch-1.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
