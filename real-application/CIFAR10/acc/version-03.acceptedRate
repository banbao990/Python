#########################
[0],loss: 19420.821337282658, train acc: 0.60402, test acc: 0.5869
#########################
[1],loss: 12465.731955379248, train acc: 0.72956, test acc: 0.7127
#########################
[2],loss: 9744.92870771885, train acc: 0.78346, test acc: 0.7469
#########################
[3],loss: 7955.107059627771, train acc: 0.81952, test acc: 0.7701
#########################
[4],loss: 6720.102681994438, train acc: 0.86674, test acc: 0.7969
#########################
[5],loss: 5611.8960610330105, train acc: 0.89038, test acc: 0.8061
#########################
[6],loss: 4782.582278549671, train acc: 0.89086, test acc: 0.7959
#########################
[7],loss: 4029.18752682209, train acc: 0.92922, test acc: 0.8205
#########################
[8],loss: 3358.02887737751, train acc: 0.93324, test acc: 0.813
#########################
[9],loss: 2824.9379630982876, train acc: 0.9541, test acc: 0.8217
#########################
[10],loss: 2346.5405827760696, train acc: 0.94588, test acc: 0.8126
#########################
[11],loss: 1980.7206463217735, train acc: 0.96192, test acc: 0.8235
#########################
[12],loss: 1657.735953092575, train acc: 0.97102, test acc: 0.8223
#########################
[13],loss: 1405.086854815483, train acc: 0.97112, test acc: 0.82
#########################
[14],loss: 1207.0180678665638, train acc: 0.9795, test acc: 0.83
#########################
[15],loss: 994.9485052227974, train acc: 0.9794, test acc: 0.8256
#########################
[16],loss: 865.2617443501949, train acc: 0.98178, test acc: 0.8306
#########################
[17],loss: 738.7349857389927, train acc: 0.9859, test acc: 0.8276
#########################
[18],loss: 709.9349492788315, train acc: 0.98556, test acc: 0.8309
#########################
[19],loss: 611.2413161695004, train acc: 0.98556, test acc: 0.8247