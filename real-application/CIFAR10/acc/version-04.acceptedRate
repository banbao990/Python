#########################
[0],loss: 21868.23671042919, train acc: 0.50406, test acc: 0.4726
#########################
[1],loss: 14806.55044221878, train acc: 0.6284, test acc: 0.6196
#########################
[2],loss: 11888.928240716457, train acc: 0.71322, test acc: 0.7013
#########################
[3],loss: 10190.96955010295, train acc: 0.7618, test acc: 0.7309
#########################
[4],loss: 9021.03841689229, train acc: 0.78248, test acc: 0.7601
#########################
[5],loss: 8120.218821823597, train acc: 0.79278, test acc: 0.7744
#########################
[6],loss: 7409.845041632652, train acc: 0.80688, test acc: 0.7774
#########################
[7],loss: 6817.746244549751, train acc: 0.82458, test acc: 0.7965
#########################
[8],loss: 6302.031856417656, train acc: 0.83752, test acc: 0.8126
#########################
[9],loss: 5871.289430886507, train acc: 0.85314, test acc: 0.8164
#########################
[10],loss: 5569.253422647715, train acc: 0.85666, test acc: 0.8222
#########################
[11],loss: 5273.619058698416, train acc: 0.8796, test acc: 0.8381
#########################
[12],loss: 4992.4532797932625, train acc: 0.86146, test acc: 0.8243
#########################
[13],loss: 4720.497207552195, train acc: 0.88252, test acc: 0.8454
#########################
[14],loss: 4938.602403879166, train acc: 0.8802, test acc: 0.8415
#########################
[15],loss: 4666.949491083622, train acc: 0.8865, test acc: 0.8508
#########################
[16],loss: 4426.320658355951, train acc: 0.89742, test acc: 0.846
#########################
[17],loss: 4219.849807143211, train acc: 0.89598, test acc: 0.8545
#########################
[18],loss: 4051.8858047425747, train acc: 0.9066, test acc: 0.8643
#########################
[19],loss: 3827.5084259808064, train acc: 0.90108, test acc: 0.8553
#########################
[20],loss: 3667.0964268147945, train acc: 0.90678, test acc: 0.8622
#########################
[21],loss: 3495.0931654274464, train acc: 0.91652, test acc: 0.8631
#########################
[22],loss: 3370.257083237171, train acc: 0.91724, test acc: 0.8652
#########################
[23],loss: 3224.6117212474346, train acc: 0.91804, test acc: 0.8627
#########################
[24],loss: 3086.4732661247253, train acc: 0.92478, test acc: 0.8682
#########################
[25],loss: 2967.2688560783863, train acc: 0.92972, test acc: 0.8718
#########################
[26],loss: 2803.6607659757137, train acc: 0.93256, test acc: 0.8753
#########################
[27],loss: 2703.884182035923, train acc: 0.93716, test acc: 0.8805
#########################
[28],loss: 2596.2520091831684, train acc: 0.93588, test acc: 0.8741
#########################
[29],loss: 2564.8824678361416, train acc: 0.94124, test acc: 0.8742
#########################
[30],loss: 2393.3642817139626, train acc: 0.9442, test acc: 0.8793
#########################
[31],loss: 2293.6748382747173, train acc: 0.94424, test acc: 0.879
#########################
[32],loss: 2204.883248656988, train acc: 0.94568, test acc: 0.8748
#########################
[33],loss: 2127.878351330757, train acc: 0.9452, test acc: 0.8721
#########################
[34],loss: 2046.3011408150196, train acc: 0.94856, test acc: 0.8722
#########################
[35],loss: 2019.8489929437637, train acc: 0.95358, test acc: 0.8731
#########################
[36],loss: 1939.1443285048008, train acc: 0.9564, test acc: 0.8826
#########################
[37],loss: 1874.3297050893307, train acc: 0.95656, test acc: 0.8792
#########################
[38],loss: 1813.1336373090744, train acc: 0.95672, test acc: 0.8813
#########################
[39],loss: 1713.8857509195805, train acc: 0.95988, test acc: 0.8826
#########################
[40],loss: 1653.8942945599556, train acc: 0.9601, test acc: 0.8818
#########################
[41],loss: 1639.1196952462196, train acc: 0.96132, test acc: 0.8859
#########################
[42],loss: 1539.052393913269, train acc: 0.96354, test acc: 0.8862
#########################
[43],loss: 1537.1726240217686, train acc: 0.95996, test acc: 0.8788
#########################
[44],loss: 1508.8919290602207, train acc: 0.96526, test acc: 0.8813
#########################
[45],loss: 1413.045794725418, train acc: 0.96582, test acc: 0.8834
#########################
[46],loss: 1341.5829364061356, train acc: 0.96974, test acc: 0.8896
#########################
[47],loss: 1352.2646905779839, train acc: 0.96918, test acc: 0.8866
#########################
[48],loss: 1277.925751209259, train acc: 0.9708, test acc: 0.8843
#########################
[49],loss: 1213.0683834552765, train acc: 0.96754, test acc: 0.8843
#########################
[50],loss: 1195.4208313822746, train acc: 0.9697, test acc: 0.8943
#########################
[51],loss: 1166.3185214400291, train acc: 0.97164, test acc: 0.8885
#########################
[52],loss: 1151.70706564188, train acc: 0.97508, test acc: 0.8911
#########################
[53],loss: 1121.918556213379, train acc: 0.97128, test acc: 0.8911
#########################
[54],loss: 1084.5647850632668, train acc: 0.97426, test acc: 0.8924
#########################
[55],loss: 993.4563600420952, train acc: 0.9769, test acc: 0.8925
#########################
[56],loss: 1004.7974395751953, train acc: 0.97172, test acc: 0.8837
#########################
[57],loss: 990.9520561695099, train acc: 0.97498, test acc: 0.8873
#########################
[58],loss: 958.1126499772072, train acc: 0.97742, test acc: 0.8869
#########################
[59],loss: 936.6713905334473, train acc: 0.97724, test acc: 0.8895
#########################
[60],loss: 884.7482527196407, train acc: 0.97428, test acc: 0.89
#########################
[61],loss: 865.4991028904915, train acc: 0.97738, test acc: 0.8863
#########################
[62],loss: 872.867794662714, train acc: 0.9792, test acc: 0.8893
#########################
[63],loss: 828.8267093300819, train acc: 0.98034, test acc: 0.888
#########################
[64],loss: 815.366974145174, train acc: 0.97818, test acc: 0.8968
#########################
[65],loss: 798.2474646866322, train acc: 0.98186, test acc: 0.8948
#########################
[66],loss: 788.2242227196693, train acc: 0.98122, test acc: 0.8919
#########################
[67],loss: 742.8772013783455, train acc: 0.98358, test acc: 0.8964
#########################
[68],loss: 756.6741146445274, train acc: 0.97808, test acc: 0.8918
#########################
[69],loss: 761.8327037096024, train acc: 0.9798, test acc: 0.8922
#########################
[70],loss: 700.8241182565689, train acc: 0.9797, test acc: 0.8899
#########################
[71],loss: 729.116880595684, train acc: 0.97942, test acc: 0.8855
#########################
[72],loss: 663.9544041752815, train acc: 0.98008, test acc: 0.8874
#########################
[74],loss: 641.7365679740906, train acc: 0.9853, test acc: 0.8916
#########################
[75],loss: 629.4005218148232, train acc: 0.98302, test acc: 0.8921
#########################
[76],loss: 624.1901452541351, train acc: 0.98708, test acc: 0.8933
#########################
[77],loss: 578.3139561414719, train acc: 0.9841, test acc: 0.8958
#########################
[78],loss: 610.4724397063255, train acc: 0.98562, test acc: 0.8945
#########################
[79],loss: 580.1241545081139, train acc: 0.98452, test acc: 0.8937
#########################
[80],loss: 584.2010064125061, train acc: 0.98436, test acc: 0.8916
#########################
[81],loss: 554.0486049056053, train acc: 0.98736, test acc: 0.8956
#########################
[82],loss: 573.7850733399391, train acc: 0.9864, test acc: 0.8996
#########################
[83],loss: 569.8774853050709, train acc: 0.98452, test acc: 0.8927
#########################
[84],loss: 533.4674760103226, train acc: 0.98854, test acc: 0.8961
#########################
[85],loss: 518.4976990222931, train acc: 0.98774, test acc: 0.8966
#########################
[86],loss: 485.89964187145233, train acc: 0.98682, test acc: 0.8932
#########################
[87],loss: 484.1133326292038, train acc: 0.98634, test acc: 0.8909
#########################
[88],loss: 497.6974439024925, train acc: 0.9881, test acc: 0.8944
#########################
[89],loss: 462.51804703474045, train acc: 0.9891, test acc: 0.8964
#########################
[90],loss: 449.57564663887024, train acc: 0.98772, test acc: 0.8918
#########################
[91],loss: 444.2469329237938, train acc: 0.98748, test acc: 0.8943
#########################
[92],loss: 443.37862902879715, train acc: 0.9892, test acc: 0.8971
#########################
[93],loss: 466.2854926586151, train acc: 0.98582, test acc: 0.8936
#########################
[94],loss: 433.3622879385948, train acc: 0.9888, test acc: 0.8972
#########################
[95],loss: 455.3627676963806, train acc: 0.98722, test acc: 0.8944
#########################
[96],loss: 427.9851993918419, train acc: 0.99054, test acc: 0.9024
#########################
[97],loss: 435.3735371828079, train acc: 0.99078, test acc: 0.8976
#########################
[98],loss: 408.23270332813263, train acc: 0.98804, test acc: 0.893
#########################
[99],loss: 419.9076403975487, train acc: 0.9908, test acc: 0.9003
#########################
[100],loss: 408.0513721704483, train acc: 0.99024, test acc: 0.8994
#########################
[101],loss: 372.3528090119362, train acc: 0.99088, test acc: 0.8953
#########################
[102],loss: 343.59898018836975, train acc: 0.9898, test acc: 0.895
#########################
[103],loss: 397.60269966721535, train acc: 0.99002, test acc: 0.8978
#########################
[104],loss: 388.33160412311554, train acc: 0.98526, test acc: 0.8877
#########################
[105],loss: 364.9158010482788, train acc: 0.99062, test acc: 0.8912
#########################
[106],loss: 361.10343074798584, train acc: 0.99048, test acc: 0.8981
#########################
[107],loss: 381.36252677440643, train acc: 0.99226, test acc: 0.9032
#########################
[108],loss: 388.08675360679626, train acc: 0.98946, test acc: 0.8926
#########################
[109],loss: 342.5336412191391, train acc: 0.99084, test acc: 0.9008
#########################
[110],loss: 355.9033296108246, train acc: 0.9914, test acc: 0.8998
#########################
[111],loss: 308.63743621110916, train acc: 0.99144, test acc: 0.8997
#########################
[112],loss: 336.22365432977676, train acc: 0.9896, test acc: 0.8995
#########################
[113],loss: 340.8754305243492, train acc: 0.9909, test acc: 0.8977
#########################
[114],loss: 310.59889459609985, train acc: 0.99086, test acc: 0.9025
#########################
[115],loss: 312.0948477983475, train acc: 0.99174, test acc: 0.8952