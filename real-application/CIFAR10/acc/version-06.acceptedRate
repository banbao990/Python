# model-VGG-06-trainacc-0.59888-testacc-0.5524-epoch-9.pkl60 
# model-VGG-06-trainacc-0.61068-testacc-0.5876-epoch-10.pkl60
# model-VGG-06-trainacc-0.62902-testacc-0.5987-epoch-11.pkl60
# model-VGG-06-trainacc-0.66348-testacc-0.6328-epoch-12.pkl60
# model-VGG-06-trainacc-0.6693-testacc-0.6481-epoch-13.pkl
# 断网导致 loss 数据缺失,其他数据因为存储了模型所以还在
#########################
[0],loss: 26881.924808502197, train acc: 0.20292, test acc: 0.2095
#########################
[1],loss: 24669.4418759346, train acc: 0.24446, test acc: 0.2435
#########################
[2],loss: 23381.675124406815, train acc: 0.2823, test acc: 0.2809
#########################
[3],loss: 22389.96774995327, train acc: 0.31448, test acc: 0.2997
#########################
[4],loss: 20997.90915477276, train acc: 0.38076, test acc: 0.3634
#########################
[5],loss: 19721.2653504014, train acc: 0.42842, test acc: 0.4129
#########################
[6],loss: 18455.436624109745, train acc: 0.49762, test acc: 0.4844
#########################
[7],loss: 17187.491658985615, train acc: 0.54826, test acc: 0.5244
#########################
[8],loss: 16081.573103368282, train acc: 0.56514, test acc: 0.5603
#########################
[9],loss: 15365.370400696993, train acc: 0.59888, test acc: 0.5524
#########################
[10],loss: 14554.047676235437, train acc: 0.61068, test acc: 0.5876
#
# lost for net-connecting
#
#########################
[13],loss: 12770.087487339973, train acc: 0.6693, test acc: 0.6481
#########################
[14],loss: 12285.562732487917, train acc: 0.69, test acc: 0.6587
#########################
[15],loss: 11943.429719090462, train acc: 0.70642, test acc: 0.6877
#########################
[16],loss: 11440.40808391571, train acc: 0.71138, test acc: 0.6792
#########################
[17],loss: 11014.866523653269, train acc: 0.72718, test acc: 0.6943
#########################
[18],loss: 10716.60888388753, train acc: 0.74178, test acc: 0.7039
#########################
[19],loss: 10390.908465117216, train acc: 0.74386, test acc: 0.691
#########################
[20],loss: 10090.470140606165, train acc: 0.75614, test acc: 0.7191
#########################
[21],loss: 9821.942278891802, train acc: 0.76106, test acc: 0.7236
#########################
[22],loss: 9640.881721377373, train acc: 0.7672, test acc: 0.7345
#########################
[23],loss: 9344.012793958187, train acc: 0.75624, test acc: 0.7121
#########################
[24],loss: 9107.85102263093, train acc: 0.7789, test acc: 0.7483
#########################
[25],loss: 8965.052777677774, train acc: 0.78618, test acc: 0.7698
#########################
[26],loss: 8698.226066291332, train acc: 0.7931, test acc: 0.7626
#########################
[27],loss: 8480.68436986208, train acc: 0.79324, test acc: 0.7526
#########################
[28],loss: 8359.763431966305, train acc: 0.79704, test acc: 0.7731
#########################
[29],loss: 8128.0093960464, train acc: 0.80096, test acc: 0.7682
#########################
[30],loss: 7987.953804552555, train acc: 0.80914, test acc: 0.7778
#########################
[31],loss: 7773.017209589481, train acc: 0.81618, test acc: 0.7781
#########################
[32],loss: 7722.067317634821, train acc: 0.81372, test acc: 0.7798
#########################
[33],loss: 7556.555116504431, train acc: 0.81788, test acc: 0.7873
#########################
[34],loss: 7354.704227387905, train acc: 0.80632, test acc: 0.7765
#########################
[35],loss: 7337.327014833689, train acc: 0.81984, test acc: 0.7881
#########################
[36],loss: 7201.925067901611, train acc: 0.83352, test acc: 0.7933
#########################
[37],loss: 6999.072935461998, train acc: 0.83498, test acc: 0.7993
#########################
[38],loss: 7004.463447213173, train acc: 0.83438, test acc: 0.7867
#########################
[39],loss: 6805.805111080408, train acc: 0.84202, test acc: 0.8025
#########################
[40],loss: 6727.082790195942, train acc: 0.83994, test acc: 0.8101
#########################
[41],loss: 6632.224698841572, train acc: 0.8393, test acc: 0.8024
#########################
[42],loss: 6578.61923032999, train acc: 0.8407, test acc: 0.8017
#########################
[43],loss: 6387.763117879629, train acc: 0.84828, test acc: 0.8018
#########################
[44],loss: 6328.795132994652, train acc: 0.84902, test acc: 0.812
#########################
[45],loss: 6263.126167953014, train acc: 0.85388, test acc: 0.81
#########################
[46],loss: 6224.354364305735, train acc: 0.85422, test acc: 0.8159
#########################
[47],loss: 6007.875105470419, train acc: 0.85606, test acc: 0.8098
#########################
[48],loss: 6063.966729015112, train acc: 0.8618, test acc: 0.8169
#########################
[49],loss: 6016.223122775555, train acc: 0.85, test acc: 0.8231
#########################
[50],loss: 5876.507282912731, train acc: 0.85372, test acc: 0.8017
#########################
[51],loss: 5898.296276092529, train acc: 0.85826, test acc: 0.7991
#########################
[52],loss: 5666.71830317378, train acc: 0.86584, test acc: 0.82
#########################
[53],loss: 5702.550559937954, train acc: 0.86446, test acc: 0.8244
#########################
[54],loss: 5599.651440650225, train acc: 0.86748, test acc: 0.824
#########################
[55],loss: 5494.9112175107, train acc: 0.86682, test acc: 0.8174
#########################
[56],loss: 5451.802125245333, train acc: 0.86876, test acc: 0.8216
#########################
[57],loss: 5398.6689004004, train acc: 0.86896, test acc: 0.8272
#########################
[58],loss: 5376.64187541604, train acc: 0.87272, test acc: 0.8205
#########################
[59],loss: 5305.333975791931, train acc: 0.8755, test acc: 0.8275
#########################
[60],loss: 5274.295924782753, train acc: 0.87212, test acc: 0.8294
#########################
[61],loss: 5247.308858782053, train acc: 0.8773, test acc: 0.8309
#########################
[62],loss: 5177.3358897566795, train acc: 0.87608, test acc: 0.8208
#########################
[63],loss: 5055.0639417767525, train acc: 0.87972, test acc: 0.8341
#########################
[64],loss: 4963.596130549908, train acc: 0.87672, test acc: 0.8239
#########################
[65],loss: 4940.832721054554, train acc: 0.88426, test acc: 0.8336
#########################
[66],loss: 4950.857363164425, train acc: 0.88444, test acc: 0.8371
#########################
[67],loss: 4886.640894293785, train acc: 0.88244, test acc: 0.8336
#########################
[68],loss: 4900.203058183193, train acc: 0.882, test acc: 0.8412
#########################
[69],loss: 4847.074349492788, train acc: 0.8816, test acc: 0.8255
#########################
[70],loss: 4774.204816639423, train acc: 0.89074, test acc: 0.8439
#########################
[71],loss: 4762.315871983767, train acc: 0.88588, test acc: 0.8335
#########################
[72],loss: 4685.129038631916, train acc: 0.88656, test acc: 0.8432
#########################
[73],loss: 4628.3762937784195, train acc: 0.88608, test acc: 0.8384
#########################
[74],loss: 4572.658458888531, train acc: 0.89142, test acc: 0.8383
#########################
[75],loss: 4608.688054412603, train acc: 0.89252, test acc: 0.8501
#########################
[76],loss: 4375.260087311268, train acc: 0.89334, test acc: 0.8374
#########################
[77],loss: 4426.492193967104, train acc: 0.8928, test acc: 0.8409
#########################
[78],loss: 4436.20179143548, train acc: 0.89692, test acc: 0.8458
#########################
[79],loss: 4426.369264811277, train acc: 0.89444, test acc: 0.8418
#########################
[80],loss: 4296.214580386877, train acc: 0.8971, test acc: 0.85
#########################
[81],loss: 4194.315112143755, train acc: 0.90134, test acc: 0.851
#########################
[82],loss: 4202.914474785328, train acc: 0.89484, test acc: 0.8412
#########################
[83],loss: 4165.880615383387, train acc: 0.89356, test acc: 0.8403
#########################
[84],loss: 4316.17273235321, train acc: 0.90004, test acc: 0.8435
#########################
[85],loss: 4244.710872709751, train acc: 0.8959, test acc: 0.8492
#########################
[86],loss: 4183.566320538521, train acc: 0.90016, test acc: 0.8443
#########################
[87],loss: 4074.8778060376644, train acc: 0.89944, test acc: 0.8437
#########################
[88],loss: 4111.502770990133, train acc: 0.90238, test acc: 0.8549
#########################
[89],loss: 4022.2024205327034, train acc: 0.90348, test acc: 0.8494
#########################
[90],loss: 4031.1846700012684, train acc: 0.90274, test acc: 0.8457
#########################
[91],loss: 4069.2570556998253, train acc: 0.90396, test acc: 0.8473
#########################
[92],loss: 3921.4545733332634, train acc: 0.90926, test acc: 0.8507
#########################
[93],loss: 3924.8499596118927, train acc: 0.90026, test acc: 0.8376
#########################
[94],loss: 3961.780037999153, train acc: 0.90838, test acc: 0.8454
#########################
[95],loss: 3825.3391648828983, train acc: 0.90864, test acc: 0.8553
#########################
[96],loss: 3903.0881555080414, train acc: 0.90808, test acc: 0.8554
#########################
[97],loss: 3844.9197331368923, train acc: 0.9063, test acc: 0.8507
#########################
[98],loss: 3878.8626191318035, train acc: 0.90318, test acc: 0.8466
#########################
[99],loss: 3839.5743716061115, train acc: 0.9084, test acc: 0.8551
#########################
[100],loss: 3763.4958577752113, train acc: 0.90954, test acc: 0.8528
#########################
[101],loss: 3808.014961361885, train acc: 0.90958, test acc: 0.8567
#########################
[102],loss: 3694.628530651331, train acc: 0.90976, test acc: 0.8472
#########################
[103],loss: 3728.644973605871, train acc: 0.91122, test acc: 0.8481
#########################
[104],loss: 3671.918030500412, train acc: 0.91298, test acc: 0.8541
#########################
[105],loss: 3645.8290525376797, train acc: 0.91486, test acc: 0.8537
#########################
[106],loss: 3626.696143180132, train acc: 0.91626, test acc: 0.8525
#########################
[107],loss: 3617.8744282722473, train acc: 0.9151, test acc: 0.8604
#########################
[108],loss: 3621.354205876589, train acc: 0.91372, test acc: 0.8562
#########################
[109],loss: 3657.70641797781, train acc: 0.91292, test acc: 0.8529
#########################
[110],loss: 3682.9786592423916, train acc: 0.91542, test acc: 0.8598